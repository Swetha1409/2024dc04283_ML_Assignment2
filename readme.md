# ğŸ“Š Machine Learning Classification Comparison Web App

## ğŸ“Œ Project Overview

This project implements and compares multiple Machine Learning classification models using a real-world dataset. The models are trained, evaluated using multiple performance metrics, and deployed using Streamlit for interactive testing.

The application allows users to:

- Upload a CSV dataset
- Select a machine learning model
- Evaluate performance
- View evaluation metrics
- Visualize confusion matrix

This project demonstrates an end-to-end Machine Learning workflow including:

- Data preprocessing
- Model training
- Model evaluation
- Model serialization
- Web deployment using Streamlit

---

## ğŸ¯ Problem Statement

The objective of this project is to build and compare multiple classification algorithms and deploy them as a web application for interactive evaluation.

The models are evaluated using the following metrics:

- Accuracy
- Precision
- Recall
- F1 Score
- AUC Score
- Matthews Correlation Coefficient (MCC)

---

## ğŸ“‚ Dataset Description

Dataset Used: **Bank Marketing Dataset**

The dataset contains customer information used to predict whether a customer subscribes to a term deposit.

### Dataset Information

- Total Records: 4521
- Total Features: 16
- Target Variable: `y` (Binary Classification)

### Example Features

- Age
- Job
- Marital Status
- Education
- Balance
- Housing Loan
- Personal Loan
- Campaign Calls
- Previous Outcome

Target Variable:

y â†’ 0 (No), 1 (Yes)


---

## ğŸ¤– Machine Learning Models Implemented

The following classification algorithms were trained:

1. Logistic Regression  
2. Decision Tree  
3. K-Nearest Neighbors (KNN)  
4. Naive Bayes  
5. Random Forest  
6. XGBoost  

---

## ğŸ“Š Evaluation Metrics

Each model is evaluated using:

- Accuracy
- Precision
- Recall
- F1 Score
- AUC Score
- Matthews Correlation Coefficient
- Confusion Matrix

---

## ğŸ“ Project Structure

project-folder/
â”‚-- app.py
â”‚-- train_models.py
â”‚-- preprocess.py
â”‚-- evaluate.py
â”‚-- requirements.txt
â”‚-- README.md
â”‚-- model/
â”‚     -- logistic.pkl
â”‚     -- decision_tree.pkl
â”‚     -- knn.pkl
â”‚     -- naive_bayes.pkl
â”‚     -- random_forest.pkl
â”‚     -- xgboost.pkl
â”‚     -- model_comparison.csv

